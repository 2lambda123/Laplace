{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "N_up = 2\n",
    "nb_dir = '/'.join(os.getcwd().split('/')[:-N_up])\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "\n",
    "N_up = 1\n",
    "nb_dir = '/'.join(os.getcwd().split('/')[:-N_up])\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_dir = str(Path('~/Code/bayesian-lottery-tickets').expanduser())\n",
    "if nb_dir not in sys.path:\n",
    "\tsys.path.append(nb_dir)\n",
    "from src.scripts.train_regression import train_loop\n",
    "from src.datasets.additional_gap_loader import load_matern_1d\n",
    "from src.utils import Datafeed, homo_Gauss_mloglike\n",
    "from src.models.MLPs import res_MLP\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define train dataloader\n",
    "X_train, y_train = load_matern_1d('../data')\n",
    "trainset = Datafeed(torch.Tensor(X_train), torch.Tensor(y_train), transform=None)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=512, shuffle=True, pin_memory=True, num_workers=2)\n",
    "\n",
    "# define test dataloader\n",
    "xlim = [-2.0, 1.9]# [-1.35, 1.6]\n",
    "X_test = torch.Tensor(np.linspace(xlim[0], xlim[1], 800)).unsqueeze(1)\n",
    "testset = Datafeed(torch.Tensor(X_test), torch.Tensor(X_test), transform=None)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=2048, shuffle=False, pin_memory=True, num_workers=2)\n",
    "\n",
    "plt.figure(dpi=100)\n",
    "plt.scatter(X_train, y_train)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct single layer neural network\n",
    "def get_model():\n",
    "    torch.manual_seed(711)\n",
    "    return torch.nn.Sequential(\n",
    "        torch.nn.Linear(1, 50), torch.nn.Tanh(), torch.nn.Linear(50, 50), torch.nn.Tanh(), torch.nn.Linear(50, 1)\n",
    "    )\n",
    "model = get_model()\n",
    "\n",
    "model_path = Path('../data/model3.pth')\n",
    "\n",
    "if model_path.exists():\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "else:\n",
    "    # train MAP\n",
    "    n_epochs = 256\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "    for i in tqdm(range(n_epochs)):\n",
    "        for X, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(X), y)\n",
    "            loss.backward()\n",
    "            optimizer.step()    \n",
    "    torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f5254706460>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_test = model(X_test).detach().cpu()\n",
    "\n",
    "plt.figure(dpi=100)\n",
    "plt.plot(X_test, y_test)\n",
    "plt.scatter(X_train, y_train, c='r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_1d_regression(X_train, y_train, y_test_mean, y_test_std, postfix):\n",
    "\tplt.figure(dpi=100)\n",
    "\tplt.scatter(X_train, y_train, c='r')\n",
    "\tplt.plot(X_test, y_test_mean, 'b')\n",
    "\tplt.fill_between(X_test[:, 0],\n",
    "\t\t\t\t\ty_test_mean[:, 0] + y_test_std[:, 0, 0],\n",
    "\t\t\t\t\ty_test_mean[:, 0] - y_test_std[:, 0, 0],\n",
    "\t\t\t\t\tcolor='b', alpha=0.3)\n",
    "\tplt.savefig(f'../data/plot_{postfix}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from laplace import Laplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ead54/miniconda3/envs/laplace/lib/python3.8/site-packages/torch/cuda/__init__.py:83: UserWarning: \n",
      "    Found GPU%d %s which is of cuda capability %d.%d.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    The minimum cuda capability supported by this library is %d.%d.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn.format(d, name, major, minor, min_arch // 10, min_arch % 10))\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    }
   ],
   "source": [
    "lap_model = Laplace(model, 'regression', subset_of_weights='all', hessian_structure='full')\n",
    "lap_model.fit(train_loader)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_test_mean, y_test_std = lap_model(X_test)\n",
    "plot_1d_regression(X_train, y_train, y_test_mean, y_test_std, 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    }
   ],
   "source": [
    "from laplace.utils import LargestMagnitudeSubnetMask, RandomSubnetMask, LastLayerSubnetMask, LargestVarianceDiagLaplaceSubnetMask, LargestVarianceSWAGSubnetMask\n",
    "from laplace import DiagLaplace\n",
    "\n",
    "for name, mask in [('mag', LargestMagnitudeSubnetMask), ('random', RandomSubnetMask), ('last', LastLayerSubnetMask), ('var-lap', LargestVarianceDiagLaplaceSubnetMask), ('var-swag', LargestVarianceSWAGSubnetMask)]:\n",
    "    n_params_subnet = 64\n",
    "    subnetmask_kwargs = dict(model=model)\n",
    "    if mask != LastLayerSubnetMask:\n",
    "        subnetmask_kwargs.update(n_params_subnet=n_params_subnet)\n",
    "    if mask == LargestVarianceSWAGSubnetMask:\n",
    "        subnetmask_kwargs.update(likelihood='regression')\n",
    "    elif mask == LargestVarianceDiagLaplaceSubnetMask:\n",
    "        diag_laplace_model = DiagLaplace(model, 'regression')\n",
    "        subnetmask_kwargs.update(diag_laplace_model=diag_laplace_model)\n",
    "    subnet_mask = mask(**subnetmask_kwargs)\n",
    "    subnet_indices = subnet_mask.select(train_loader)\n",
    "\n",
    "    lap_model = Laplace(model, 'regression', subset_of_weights='subnetwork', hessian_structure='full', subnetwork_indices=subnet_indices)\n",
    "    lap_model.fit(train_loader)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_test_mean, y_test_std = lap_model(X_test)\n",
    "    plot_1d_regression(X_train, y_train, y_test_mean, y_test_std, f'{name}_{n_params_subnet}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(78.8184)\n",
      "n_params_subnet=  1: 2700 (logdet=72.824) [0.34s]\n",
      "n_params_subnet=  2: 2692 (logdet=66.859) [0.46s]\n",
      "n_params_subnet=  3: 2660 (logdet=61.785) [0.58s]\n",
      "n_params_subnet=  4: 2666 (logdet=56.716) [0.71s]\n",
      "n_params_subnet=  5: 2663 (logdet=52.708) [0.93s]\n",
      "n_params_subnet=  6: 2677 (logdet=48.876) [1.07s]\n",
      "n_params_subnet=  7: 2686 (logdet=45.082) [1.21s]\n",
      "n_params_subnet=  8: 2699 (logdet=41.557) [1.34s]\n",
      "n_params_subnet=  9: 2661 (logdet=38.891) [1.49s]\n",
      "n_params_subnet= 10:   97 (logdet=37.070) [1.64s]\n",
      "n_params_subnet= 11: 2650 (logdet=35.390) [1.79s]\n",
      "n_params_subnet= 12:   21 (logdet=33.885) [1.95s]\n",
      "n_params_subnet= 13: 2651 (logdet=32.387) [2.18s]\n",
      "n_params_subnet= 14: 2656 (logdet=31.176) [2.34s]\n",
      "n_params_subnet= 15: 2613 (logdet=30.393) [2.49s]\n",
      "n_params_subnet= 16: 2611 (logdet=29.764) [2.64s]\n",
      "n_params_subnet= 17: 2662 (logdet=29.149) [2.80s]\n",
      "n_params_subnet= 18: 2657 (logdet=28.547) [2.97s]\n",
      "n_params_subnet= 19:   71 (logdet=27.961) [3.14s]\n",
      "n_params_subnet= 20: 2694 (logdet=27.450) [3.34s]\n",
      "n_params_subnet= 21: 2687 (logdet=26.947) [3.52s]\n",
      "n_params_subnet= 22: 2698 (logdet=26.445) [3.79s]\n",
      "n_params_subnet= 23:   58 (logdet=25.982) [3.98s]\n",
      "n_params_subnet= 24: 2668 (logdet=25.574) [4.18s]\n",
      "n_params_subnet= 25:    0 (logdet=25.174) [4.36s]\n",
      "n_params_subnet= 26:  771 (logdet=24.801) [4.55s]\n",
      "n_params_subnet= 27: 2680 (logdet=24.442) [4.75s]\n",
      "n_params_subnet= 28: 2664 (logdet=24.068) [4.95s]\n",
      "n_params_subnet= 29: 2616 (logdet=23.717) [5.15s]\n",
      "n_params_subnet= 30: 2682 (logdet=23.361) [5.36s]\n",
      "n_params_subnet= 31:   47 (logdet=23.040) [5.65s]\n",
      "n_params_subnet= 32:  671 (logdet=22.725) [5.86s]\n",
      "n_params_subnet= 33: 2600 (logdet=22.415) [6.07s]\n",
      "n_params_subnet= 34: 2693 (logdet=22.120) [6.30s]\n",
      "n_params_subnet= 35:   48 (logdet=21.843) [6.52s]\n",
      "n_params_subnet= 36: 2696 (logdet=21.541) [6.76s]\n",
      "n_params_subnet= 37: 2669 (logdet=21.274) [6.98s]\n",
      "n_params_subnet= 38: 2610 (logdet=21.019) [7.22s]\n",
      "n_params_subnet= 39:  923 (logdet=20.771) [7.45s]\n",
      "n_params_subnet= 40:  793 (logdet=20.529) [7.78s]\n",
      "n_params_subnet= 41: 2675 (logdet=20.271) [8.02s]\n",
      "n_params_subnet= 42:   93 (logdet=20.042) [8.28s]\n",
      "n_params_subnet= 43:    5 (logdet=19.821) [8.54s]\n",
      "n_params_subnet= 44: 2676 (logdet=19.602) [8.81s]\n",
      "n_params_subnet= 45:   78 (logdet=19.385) [9.07s]\n",
      "n_params_subnet= 46:  123 (logdet=19.172) [9.35s]\n",
      "n_params_subnet= 47: 2697 (logdet=18.975) [9.63s]\n",
      "n_params_subnet= 48:  908 (logdet=18.779) [9.92s]\n",
      "n_params_subnet= 49: 2655 (logdet=18.575) [10.19s]\n",
      "n_params_subnet= 50: 2636 (logdet=18.381) [10.57s]\n",
      "n_params_subnet= 51:  693 (logdet=18.193) [10.88s]\n",
      "n_params_subnet= 52: 2670 (logdet=17.998) [11.20s]\n",
      "n_params_subnet= 53:   79 (logdet=17.814) [11.50s]\n",
      "n_params_subnet= 54:  779 (logdet=17.630) [11.85s]\n",
      "n_params_subnet= 55:  621 (logdet=17.456) [12.18s]\n",
      "n_params_subnet= 56: 2671 (logdet=17.254) [12.54s]\n",
      "n_params_subnet= 57: 2627 (logdet=17.086) [12.86s]\n",
      "n_params_subnet= 58: 2659 (logdet=16.895) [13.22s]\n",
      "n_params_subnet= 59:  108 (logdet=16.728) [13.66s]\n",
      "n_params_subnet= 60:  918 (logdet=16.571) [14.05s]\n",
      "n_params_subnet= 61:   73 (logdet=16.415) [14.41s]\n",
      "n_params_subnet= 62: 2665 (logdet=16.261) [14.82s]\n",
      "n_params_subnet= 63: 2691 (logdet=16.095) [15.20s]\n",
      "n_params_subnet= 64:  750 (logdet=15.941) [15.62s]\n",
      "n_params_subnet= 65:  643 (logdet=15.796) [16.00s]\n",
      "n_params_subnet= 66: 2658 (logdet=15.634) [16.41s]\n",
      "n_params_subnet= 67:   29 (logdet=15.489) [16.92s]\n",
      "n_params_subnet= 68: 1921 (logdet=15.348) [17.36s]\n",
      "n_params_subnet= 69: 2678 (logdet=15.208) [17.80s]\n",
      "n_params_subnet= 70: 2685 (logdet=15.059) [18.28s]\n",
      "n_params_subnet= 71:  118 (logdet=14.922) [18.74s]\n",
      "n_params_subnet= 72:  922 (logdet=14.788) [19.24s]\n",
      "n_params_subnet= 73:  767 (logdet=14.656) [19.66s]\n",
      "n_params_subnet= 74: 1473 (logdet=14.525) [20.17s]\n",
      "n_params_subnet= 75:  650 (logdet=14.394) [20.64s]\n",
      "n_params_subnet= 76:   51 (logdet=14.271) [21.25s]\n",
      "n_params_subnet= 77:  122 (logdet=14.151) [21.75s]\n",
      "n_params_subnet= 78:  629 (logdet=14.033) [22.31s]\n",
      "n_params_subnet= 79:  928 (logdet=13.916) [22.85s]\n",
      "n_params_subnet= 80: 1943 (logdet=13.799) [23.44s]\n",
      "n_params_subnet= 81: 2653 (logdet=13.676) [23.95s]\n",
      "n_params_subnet= 82: 1458 (logdet=13.561) [24.53s]\n",
      "n_params_subnet= 83: 2695 (logdet=13.427) [25.10s]\n",
      "n_params_subnet= 84: 2690 (logdet=13.308) [25.71s]\n",
      "n_params_subnet= 85:  770 (logdet=13.194) [26.38s]\n",
      "n_params_subnet= 86:   70 (logdet=13.082) [27.01s]\n",
      "n_params_subnet= 87:  679 (logdet=12.974) [27.65s]\n",
      "n_params_subnet= 88:  128 (logdet=12.871) [28.31s]\n",
      "n_params_subnet= 89:   27 (logdet=12.767) [28.90s]\n",
      "n_params_subnet= 90: 2652 (logdet=12.618) [29.56s]\n",
      "n_params_subnet= 91:  906 (logdet=12.516) [30.20s]\n",
      "n_params_subnet= 92:  600 (logdet=12.414) [30.88s]\n",
      "n_params_subnet= 93:   72 (logdet=12.312) [31.54s]\n",
      "n_params_subnet= 94:   98 (logdet=12.211) [32.25s]\n",
      "n_params_subnet= 95: 2688 (logdet=12.106) [33.04s]\n",
      "n_params_subnet= 96:  766 (logdet=12.006) [33.79s]\n",
      "n_params_subnet= 97: 1900 (logdet=11.908) [34.43s]\n",
      "n_params_subnet= 98: 1468 (logdet=11.810) [35.16s]\n",
      "n_params_subnet= 99: 2679 (logdet=11.715) [35.88s]\n",
      "n_params_subnet=100:   69 (logdet=11.622) [36.64s]\n",
      "n_params_subnet=101:  106 (logdet=11.530) [37.38s]\n",
      "n_params_subnet=102:  617 (logdet=11.438) [38.18s]\n",
      "n_params_subnet=103:  901 (logdet=11.346) [38.97s]\n",
      "n_params_subnet=104: 2673 (logdet=11.240) [39.89s]\n",
      "n_params_subnet=105:  763 (logdet=11.150) [40.63s]\n",
      "n_params_subnet=106: 1929 (logdet=11.061) [41.45s]\n",
      "n_params_subnet=107: 1472 (logdet=10.974) [42.25s]\n",
      "n_params_subnet=108:  667 (logdet=10.886) [43.11s]\n",
      "n_params_subnet=109:   56 (logdet=10.803) [43.93s]\n",
      "n_params_subnet=110:  911 (logdet=10.719) [44.83s]\n",
      "n_params_subnet=111:  101 (logdet=10.636) [45.71s]\n",
      "n_params_subnet=112: 2684 (logdet=10.523) [46.63s]\n",
      "n_params_subnet=113: 2689 (logdet=10.436) [47.52s]\n",
      "n_params_subnet=114:  795 (logdet=10.354) [48.47s]\n",
      "n_params_subnet=115:   76 (logdet=10.273) [49.38s]\n",
      "n_params_subnet=116:  620 (logdet=10.193) [50.35s]\n",
      "n_params_subnet=117: 1917 (logdet=10.115) [51.28s]\n",
      "n_params_subnet=118:    8 (logdet=10.037) [52.30s]\n",
      "n_params_subnet=119:   95 (logdet=9.959) [53.32s]\n",
      "n_params_subnet=120: 1478 (logdet=9.881) [54.37s]\n",
      "n_params_subnet=121:  670 (logdet=9.806) [55.29s]\n",
      "n_params_subnet=122:  111 (logdet=9.732) [56.41s]\n",
      "n_params_subnet=123:  769 (logdet=9.657) [57.43s]\n",
      "n_params_subnet=124:  932 (logdet=9.583) [58.50s]\n",
      "n_params_subnet=125:   26 (logdet=9.511) [59.55s]\n",
      "n_params_subnet=126:  616 (logdet=9.439) [60.67s]\n",
      "n_params_subnet=127:   55 (logdet=9.369) [61.80s]\n",
      "n_params_subnet=128:  783 (logdet=9.301) [62.98s]\n",
      "n_params_subnet=129:  927 (logdet=9.232) [64.00s]\n",
      "n_params_subnet=130: 1920 (logdet=9.163) [65.15s]\n",
      "n_params_subnet=131: 1456 (logdet=9.095) [66.38s]\n",
      "n_params_subnet=132:  127 (logdet=9.028) [67.58s]\n",
      "n_params_subnet=133:  666 (logdet=8.961) [68.76s]\n",
      "n_params_subnet=134:   87 (logdet=8.894) [70.03s]\n",
      "n_params_subnet=135:   82 (logdet=8.830) [71.29s]\n",
      "n_params_subnet=136:  613 (logdet=8.766) [72.60s]\n",
      "n_params_subnet=137: 2672 (logdet=8.686) [73.75s]\n",
      "n_params_subnet=138:  787 (logdet=8.622) [75.04s]\n",
      "n_params_subnet=139:   19 (logdet=8.558) [76.32s]\n",
      "n_params_subnet=140: 2681 (logdet=8.495) [77.78s]\n",
      "n_params_subnet=141:  905 (logdet=8.432) [79.10s]\n",
      "n_params_subnet=142:  105 (logdet=8.370) [80.49s]\n",
      "n_params_subnet=143: 1916 (logdet=8.308) [81.91s]\n",
      "n_params_subnet=144: 1451 (logdet=8.245) [83.35s]\n",
      "n_params_subnet=145: 2654 (logdet=8.172) [84.63s]\n",
      "n_params_subnet=146:  799 (logdet=8.113) [86.06s]\n",
      "n_params_subnet=147:  619 (logdet=8.053) [87.46s]\n",
      "n_params_subnet=148:  663 (logdet=7.995) [88.92s]\n",
      "n_params_subnet=149:    1 (logdet=7.936) [90.41s]\n",
      "n_params_subnet=150: 1461 (logdet=7.877) [92.03s]\n",
      "n_params_subnet=151: 2683 (logdet=7.807) [93.57s]\n",
      "n_params_subnet=152:  132 (logdet=7.749) [95.16s]\n",
      "n_params_subnet=153:  944 (logdet=7.692) [96.56s]\n",
      "n_params_subnet=154: 1913 (logdet=7.634) [98.12s]\n",
      "n_params_subnet=155:   65 (logdet=7.576) [99.67s]\n",
      "n_params_subnet=156:  789 (logdet=7.521) [101.29s]\n",
      "n_params_subnet=157:  645 (logdet=7.466) [102.88s]\n",
      "n_params_subnet=158:  934 (logdet=7.411) [104.55s]\n",
      "n_params_subnet=159:   50 (logdet=7.357) [106.34s]\n",
      "n_params_subnet=160:  125 (logdet=7.303) [108.08s]\n",
      "n_params_subnet=161:   14 (logdet=7.249) [109.61s]\n",
      "n_params_subnet=162:  669 (logdet=7.195) [111.35s]\n",
      "n_params_subnet=163: 1482 (logdet=7.142) [113.06s]\n",
      "n_params_subnet=164:   99 (logdet=7.089) [114.83s]\n",
      "n_params_subnet=165: 1919 (logdet=7.037) [116.54s]\n",
      "n_params_subnet=166:  752 (logdet=6.984) [118.38s]\n",
      "n_params_subnet=167:  633 (logdet=6.933) [120.22s]\n",
      "n_params_subnet=168:  925 (logdet=6.882) [122.20s]\n",
      "n_params_subnet=169:  695 (logdet=6.832) [123.90s]\n",
      "n_params_subnet=170: 2674 (logdet=6.778) [125.91s]\n",
      "n_params_subnet=171: 1477 (logdet=6.728) [127.95s]\n",
      "n_params_subnet=172: 1945 (logdet=6.678) [130.05s]\n",
      "n_params_subnet=173:   43 (logdet=6.628) [132.11s]\n",
      "n_params_subnet=174:  786 (logdet=6.579) [134.18s]\n",
      "n_params_subnet=175:  134 (logdet=6.531) [136.34s]\n",
      "n_params_subnet=176:  637 (logdet=6.483) [138.54s]\n",
      "n_params_subnet=177:   77 (logdet=6.435) [140.47s]\n",
      "n_params_subnet=178: 1933 (logdet=6.388) [142.70s]\n",
      "n_params_subnet=179:   57 (logdet=6.340) [144.90s]\n",
      "n_params_subnet=180:   80 (logdet=6.293) [147.19s]\n",
      "n_params_subnet=181:  798 (logdet=6.246) [149.38s]\n",
      "n_params_subnet=182: 1494 (logdet=6.199) [151.67s]\n",
      "n_params_subnet=183:   83 (logdet=6.153) [153.87s]\n",
      "n_params_subnet=184:  947 (logdet=6.108) [156.19s]\n",
      "n_params_subnet=185:  649 (logdet=6.062) [158.21s]\n",
      "n_params_subnet=186:  683 (logdet=6.017) [160.47s]\n",
      "n_params_subnet=187:  144 (logdet=5.973) [162.83s]\n",
      "n_params_subnet=188: 1949 (logdet=5.928) [165.16s]\n",
      "n_params_subnet=189: 1455 (logdet=5.884) [167.33s]\n",
      "n_params_subnet=190:  788 (logdet=5.842) [169.79s]\n",
      "n_params_subnet=191:  687 (logdet=5.799) [172.34s]\n",
      "n_params_subnet=192:   66 (logdet=5.756) [174.81s]\n",
      "n_params_subnet=193: 1937 (logdet=5.714) [177.08s]\n",
      "n_params_subnet=194:   53 (logdet=5.671) [179.64s]\n",
      "n_params_subnet=195:  648 (logdet=5.630) [182.14s]\n",
      "n_params_subnet=196: 1484 (logdet=5.588) [184.87s]\n",
      "n_params_subnet=197:  699 (logdet=5.548) [187.23s]\n",
      "n_params_subnet=198:   49 (logdet=5.507) [189.94s]\n",
      "n_params_subnet=199:  759 (logdet=5.468) [192.60s]\n",
      "n_params_subnet=200:  147 (logdet=5.428) [195.27s]\n",
      "n_params_subnet=201:  639 (logdet=5.389) [197.77s]\n",
      "n_params_subnet=202:   90 (logdet=5.350) [200.48s]\n",
      "n_params_subnet=203: 1948 (logdet=5.311) [203.26s]\n",
      "n_params_subnet=204:   61 (logdet=5.272) [205.97s]\n",
      "n_params_subnet=205: 1475 (logdet=5.234) [208.75s]\n",
      "n_params_subnet=206:  636 (logdet=5.196) [211.68s]\n",
      "n_params_subnet=207:  930 (logdet=5.158) [214.56s]\n",
      "n_params_subnet=208:  792 (logdet=5.121) [217.53s]\n",
      "n_params_subnet=209:  698 (logdet=5.084) [219.95s]\n",
      "n_params_subnet=210: 1936 (logdet=5.048) [222.64s]\n",
      "n_params_subnet=211:  602 (logdet=5.011) [225.32s]\n",
      "n_params_subnet=212: 1497 (logdet=4.976) [228.12s]\n",
      "n_params_subnet=213:   64 (logdet=4.940) [230.80s]\n",
      "n_params_subnet=214:  765 (logdet=4.905) [233.69s]\n",
      "n_params_subnet=215:  686 (logdet=4.871) [236.67s]\n",
      "n_params_subnet=216: 1902 (logdet=4.836) [239.61s]\n",
      "n_params_subnet=217:   67 (logdet=4.801) [242.21s]\n",
      "n_params_subnet=218:   68 (logdet=4.768) [245.10s]\n",
      "n_params_subnet=219:   20 (logdet=4.733) [247.97s]\n",
      "n_params_subnet=220:  652 (logdet=4.700) [250.95s]\n",
      "n_params_subnet=221:  130 (logdet=4.668) [253.81s]\n",
      "n_params_subnet=222:    7 (logdet=4.634) [256.91s]\n",
      "n_params_subnet=223:  781 (logdet=4.601) [260.05s]\n",
      "n_params_subnet=224:  638 (logdet=4.569) [263.32s]\n",
      "n_params_subnet=225: 1939 (logdet=4.537) [266.12s]\n",
      "n_params_subnet=226:  689 (logdet=4.506) [269.22s]\n",
      "n_params_subnet=227:  785 (logdet=4.475) [272.30s]\n",
      "n_params_subnet=228:   22 (logdet=4.445) [275.47s]\n",
      "n_params_subnet=229: 1480 (logdet=4.414) [278.55s]\n",
      "n_params_subnet=230:  609 (logdet=4.385) [281.88s]\n",
      "n_params_subnet=231:   63 (logdet=4.356) [285.13s]\n",
      "n_params_subnet=232: 2644 (logdet=4.327) [288.51s]\n",
      "n_params_subnet=233: 1938 (logdet=4.298) [291.60s]\n",
      "n_params_subnet=234:    6 (logdet=4.270) [294.90s]\n",
      "n_params_subnet=235: 2667 (logdet=4.239) [298.19s]\n",
      "n_params_subnet=236:   85 (logdet=4.210) [301.59s]\n",
      "n_params_subnet=237:   24 (logdet=4.180) [304.91s]\n",
      "n_params_subnet=238:  688 (logdet=4.152) [308.44s]\n",
      "n_params_subnet=239: 2647 (logdet=4.125) [311.94s]\n",
      "n_params_subnet=240: 2343 (logdet=4.097) [315.57s]\n",
      "n_params_subnet=241:   16 (logdet=4.068) [318.80s]\n",
      "n_params_subnet=242:  642 (logdet=4.041) [322.32s]\n",
      "n_params_subnet=243:   40 (logdet=4.012) [325.92s]\n",
      "n_params_subnet=244:  760 (logdet=3.985) [329.58s]\n",
      "n_params_subnet=245: 2317 (logdet=3.958) [333.12s]\n",
      "n_params_subnet=246:  914 (logdet=3.931) [336.91s]\n",
      "n_params_subnet=247:   23 (logdet=3.904) [340.66s]\n",
      "n_params_subnet=248:  615 (logdet=3.878) [344.49s]\n",
      "n_params_subnet=249: 2320 (logdet=3.852) [347.93s]\n",
      "n_params_subnet=250: 1909 (logdet=3.826) [351.71s]\n",
      "n_params_subnet=251: 2473 (logdet=3.800) [355.48s]\n",
      "n_params_subnet=252:   74 (logdet=3.774) [359.48s]\n",
      "n_params_subnet=253: 2329 (logdet=3.748) [363.25s]\n",
      "n_params_subnet=254:   86 (logdet=3.721) [367.37s]\n",
      "n_params_subnet=255:  659 (logdet=3.696) [371.46s]\n",
      "n_params_subnet=256: 2321 (logdet=3.671) [375.66s]\n"
     ]
    }
   ],
   "source": [
    "from laplace.utils import GreedyMarginalLikelihoodSubnetMask\n",
    "from laplace import FullLaplace\n",
    "\n",
    "n_params_subnet = 256\n",
    "laplace_model = FullLaplace(model, 'regression')\n",
    "subnet_mask = GreedyMarginalLikelihoodSubnetMask(model, n_params_subnet, laplace_model)\n",
    "subnet_indices = subnet_mask.select(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    }
   ],
   "source": [
    "lap_model = Laplace(model, 'regression', subset_of_weights='subnetwork', hessian_structure='full', subnetwork_indices=subnet_indices)\n",
    "lap_model.fit(train_loader)\n",
    "#lap_model.prior_precision = n_params_subnet / 2701\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_test_mean, y_test_std = lap_model(X_test)\n",
    "plot_1d_regression(X_train, y_train, y_test_mean, y_test_std, f'greedy_min_diff_{n_params_subnet}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "741877d273ff1bee2a68da57eeef1a926621b7647b85c08277c30c84a57f06f9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('laplace': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
